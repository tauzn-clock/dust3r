{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dust3r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#Set current location to the location of the script\n",
    "os.chdir(os.path.dirname(\"/dust3r/playground.ipynb\"))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display imgs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def display_img(img):\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dust3r.inference import inference\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading model from checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n",
      "<All keys matched successfully>\n",
      ">> Loading a list of 2 images\n",
      " - adding croco/assets/Chateau1.png with resolution 224x224 --> 512x384\n",
      " - adding croco/assets/Chateau2.png with resolution 224x224 --> 512x384\n",
      " (Found 2 images)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "batch_size = 1\n",
    "schedule = 'cosine'\n",
    "lr = 0.01\n",
    "niter = 300\n",
    "\n",
    "model_name = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
    "# you can put the path to a local checkpoint in model_name if needed\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)\n",
    "# load_images can take a list of images or a directory\n",
    "images = load_images(['croco/assets/Chateau1.png', 'croco/assets/Chateau2.png'], size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)\n",
    "output = inference(pairs, model, device, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "view1, pred1 = output['view1'], output['pred1']\n",
    "view2, pred2 = output['view2'], output['pred2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (1*,0*) score=31.983793258666992\n",
      " init loss = 0.004671978764235973\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps', 'im_poses', 'im_focals']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:17<00:00, 16.94it/s, lr=1.27413e-06 loss=0.00293712]\n"
     ]
    }
   ],
   "source": [
    "scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer)\n",
    "loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = scene.imgs\n",
    "focals = scene.get_focals()\n",
    "poses = scene.get_im_poses()\n",
    "pts3d = scene.get_pts3d()\n",
    "confidence_masks = scene.get_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.0387, -0.0226,  0.1448],\n",
      "         [ 0.0614, -0.0179,  0.1242],\n",
      "         [ 0.0617, -0.0179,  0.1240],\n",
      "         ...,\n",
      "         [ 0.0638, -0.0294,  0.2559],\n",
      "         [ 0.0638, -0.0294,  0.2566],\n",
      "         [ 0.0627, -0.0298,  0.2597]],\n",
      "\n",
      "        [[ 0.0512, -0.0199,  0.1334],\n",
      "         [ 0.0664, -0.0168,  0.1196],\n",
      "         [ 0.0655, -0.0170,  0.1206],\n",
      "         ...,\n",
      "         [ 0.0616, -0.0299,  0.2613],\n",
      "         [ 0.0626, -0.0296,  0.2595],\n",
      "         [ 0.0617, -0.0300,  0.2621]],\n",
      "\n",
      "        [[ 0.0584, -0.0183,  0.1267],\n",
      "         [ 0.0673, -0.0165,  0.1188],\n",
      "         [ 0.0670, -0.0166,  0.1192],\n",
      "         ...,\n",
      "         [ 0.0633, -0.0291,  0.2573],\n",
      "         [ 0.0631, -0.0293,  0.2582],\n",
      "         [ 0.0622, -0.0296,  0.2608]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0512,  0.0240,  0.1300],\n",
      "         [ 0.0516,  0.0239,  0.1298],\n",
      "         [ 0.0518,  0.0239,  0.1297],\n",
      "         ...,\n",
      "         [ 0.1025,  0.0252,  0.1554],\n",
      "         [ 0.1024,  0.0253,  0.1559],\n",
      "         [ 0.1024,  0.0254,  0.1563]],\n",
      "\n",
      "        [[ 0.0523,  0.0239,  0.1290],\n",
      "         [ 0.0518,  0.0240,  0.1296],\n",
      "         [ 0.0526,  0.0238,  0.1290],\n",
      "         ...,\n",
      "         [ 0.1026,  0.0253,  0.1553],\n",
      "         [ 0.1025,  0.0254,  0.1556],\n",
      "         [ 0.1022,  0.0256,  0.1568]],\n",
      "\n",
      "        [[ 0.0545,  0.0234,  0.1271],\n",
      "         [ 0.0544,  0.0235,  0.1273],\n",
      "         [ 0.0533,  0.0238,  0.1284],\n",
      "         ...,\n",
      "         [ 0.1023,  0.0256,  0.1559],\n",
      "         [ 0.1028,  0.0254,  0.1551],\n",
      "         [ 0.1026,  0.0255,  0.1558]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>), tensor([[[-0.0377, -0.0301,  0.1902],\n",
      "         [-0.0432, -0.0346,  0.2187],\n",
      "         [-0.0450, -0.0361,  0.2287],\n",
      "         ...,\n",
      "         [ 0.0538, -0.0411,  0.2693],\n",
      "         [ 0.0537, -0.0409,  0.2680],\n",
      "         [ 0.0545, -0.0413,  0.2707]],\n",
      "\n",
      "        [[-0.0332, -0.0263,  0.1672],\n",
      "         [-0.0291, -0.0232,  0.1475],\n",
      "         [-0.0297, -0.0237,  0.1508],\n",
      "         ...,\n",
      "         [ 0.0543, -0.0413,  0.2721],\n",
      "         [ 0.0541, -0.0410,  0.2700],\n",
      "         [ 0.0551, -0.0415,  0.2736]],\n",
      "\n",
      "        [[-0.0288, -0.0228,  0.1455],\n",
      "         [-0.0262, -0.0208,  0.1327],\n",
      "         [-0.0260, -0.0206,  0.1320],\n",
      "         ...,\n",
      "         [ 0.0540, -0.0409,  0.2706],\n",
      "         [ 0.0545, -0.0411,  0.2720],\n",
      "         [ 0.0548, -0.0411,  0.2721]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0491,  0.0339,  0.2431],\n",
      "         [-0.0493,  0.0342,  0.2452],\n",
      "         [-0.0494,  0.0344,  0.2465],\n",
      "         ...,\n",
      "         [ 0.0459,  0.0340,  0.2347],\n",
      "         [ 0.0444,  0.0328,  0.2265],\n",
      "         [ 0.0465,  0.0343,  0.2363]],\n",
      "\n",
      "        [[-0.0483,  0.0335,  0.2389],\n",
      "         [-0.0484,  0.0338,  0.2404],\n",
      "         [-0.0484,  0.0339,  0.2413],\n",
      "         ...,\n",
      "         [ 0.0458,  0.0342,  0.2346],\n",
      "         [ 0.0442,  0.0328,  0.2252],\n",
      "         [ 0.0446,  0.0330,  0.2267]],\n",
      "\n",
      "        [[-0.0475,  0.0332,  0.2350],\n",
      "         [-0.0475,  0.0333,  0.2359],\n",
      "         [-0.0486,  0.0342,  0.2425],\n",
      "         ...,\n",
      "         [ 0.0447,  0.0335,  0.2289],\n",
      "         [ 0.0438,  0.0327,  0.2234],\n",
      "         [ 0.0440,  0.0327,  0.2233]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "print(pts3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 512, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(img)):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(img[i])):\n\u001b[0;32m---> 17\u001b[0m         img[i][j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m display_img(img)\n",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "for img in pts3d:\n",
    "    img = img.detach().cpu().numpy()\n",
    "    #Convert from bool to int\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            img[i][j] = int(img[i][j])\n",
    "    display_img(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
