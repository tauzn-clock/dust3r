{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dust3r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/dust3r\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import torch\n",
    "\n",
    "from dust3r.inference import inference, inference_with_mask\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "\n",
    "DATA_PATH = \"/dust3r/masked_dust3r/data/jackal_training_data_0\"\n",
    "IMG_FILE_EXTENSION = \".png\"\n",
    "MASK_FILE_EXTENSION = \".png\"\n",
    "device = 'cuda'\n",
    "batch_size = 1\n",
    "schedule = 'cosine'\n",
    "lr = 0.01\n",
    "niter = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading model from checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# you can put the path to a local checkpoint in model_name if needed\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAsymmetricCroCo3DStereo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/dust3r/dust3r/model.py:77\u001b[0m, in \u001b[0;36mAsymmetricCroCo3DStereo.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(pretrained_model_name_or_path):\n\u001b[0;32m---> 77\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(AsymmetricCroCo3DStereo, \u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/dust3r/dust3r/model.py:37\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path, device, verbose)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstantiating : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m s \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mload_state_dict(ckpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m], strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "File \u001b[0;32m/dust3r/dust3r/model.py:67\u001b[0m, in \u001b[0;36mAsymmetricCroCo3DStereo.__init__\u001b[0;34m(self, output_mode, head_type, depth_mode, conf_mode, freeze, landscape_only, patch_embed_cls, **croco_kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed_cls \u001b[38;5;241m=\u001b[39m patch_embed_cls\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcroco_args \u001b[38;5;241m=\u001b[39m fill_default_args(croco_kwargs, \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcroco_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# dust3r specific initialization\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_blocks2 \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_blocks)\n",
      "File \u001b[0;32m/dust3r/croco/models/croco.py:69\u001b[0m, in \u001b[0;36mCroCoNet.__init__\u001b[0;34m(self, img_size, patch_size, mask_ratio, enc_embed_dim, enc_depth, enc_num_heads, dec_embed_dim, dec_depth, dec_num_heads, mlp_ratio, norm_layer, norm_im2_in_dec, pos_embed)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_depth \u001b[38;5;241m=\u001b[39m enc_depth\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_embed_dim \u001b[38;5;241m=\u001b[39m enc_embed_dim\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_blocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m     70\u001b[0m     Block(enc_embed_dim, enc_num_heads, mlp_ratio, qkv_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, norm_layer\u001b[38;5;241m=\u001b[39mnorm_layer, rope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrope)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(enc_depth)])\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_norm \u001b[38;5;241m=\u001b[39m norm_layer(enc_embed_dim)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# masked tokens \u001b[39;00m\n",
      "File \u001b[0;32m/dust3r/croco/models/croco.py:70\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_depth \u001b[38;5;241m=\u001b[39m enc_depth\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_embed_dim \u001b[38;5;241m=\u001b[39m enc_embed_dim\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_blocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[0;32m---> 70\u001b[0m     \u001b[43mBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_embed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_num_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqkv_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(enc_depth)])\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_norm \u001b[38;5;241m=\u001b[39m norm_layer(enc_embed_dim)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# masked tokens \u001b[39;00m\n",
      "File \u001b[0;32m/dust3r/croco/models/blocks.py:125\u001b[0m, in \u001b[0;36mBlock.__init__\u001b[0;34m(self, dim, num_heads, mlp_ratio, qkv_bias, drop, attn_drop, drop_path, act_layer, norm_layer, rope)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2 \u001b[38;5;241m=\u001b[39m norm_layer(dim)\n\u001b[1;32m    124\u001b[0m mlp_hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(dim \u001b[38;5;241m*\u001b[39m mlp_ratio)\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m \u001b[43mMlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlp_hidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mact_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dust3r/croco/models/blocks.py:67\u001b[0m, in \u001b[0;36mMlp.__init__\u001b[0;34m(self, in_features, hidden_features, out_features, act_layer, bias, drop)\u001b[0m\n\u001b[1;32m     64\u001b[0m bias \u001b[38;5;241m=\u001b[39m to_2tuple(bias)\n\u001b[1;32m     65\u001b[0m drop_probs \u001b[38;5;241m=\u001b[39m to_2tuple(drop)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact \u001b[38;5;241m=\u001b[39m act_layer()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(drop_probs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:109\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:459\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[1;32m    457\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_name = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
    "# you can put the path to a local checkpoint in model_name if needed\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading a list of 10 images\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/0.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/1.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/2.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/3.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/4.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/5.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/6.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/7.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/8.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/9.png with resolution 1280x720 --> 512x288\n",
      " (Found 10 images)\n"
     ]
    }
   ],
   "source": [
    "images_array = []\n",
    "masks_array = []\n",
    "\n",
    "for i in range(10):\n",
    "    images_array.append(os.path.join(DATA_PATH,\"masked_images/{}{}\".format(i,IMG_FILE_EXTENSION)))\n",
    "    masks_array.append(os.path.join(DATA_PATH,\"masks/{}{}\".format(i,MASK_FILE_EXTENSION)))\n",
    "images = load_images(images_array, size=512, verbose=True)\n",
    "\n",
    "masks = []\n",
    "\n",
    "for i in range(len(masks_array)):\n",
    "    mask = Image.open(masks_array[i]).convert('L')\n",
    "    _,_,H,W = images[i][\"img\"].shape\n",
    "    mask = mask.resize((W,H))\n",
    "\n",
    "    mask = np.array(mask)\n",
    "    mask = torch.tensor(mask).to(device)/255\n",
    "    masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Inference with model on 90 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/90 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 90/90 [00:38<00:00,  2.34it/s]\n"
     ]
    }
   ],
   "source": [
    "pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)\n",
    "output = inference_with_mask(pairs, model, device, masks, 3.0, batch_size=batch_size)\n",
    "\n",
    "view1, pred1 = output['view1'], output['pred1']\n",
    "view2, pred2 = output['view2'], output['pred2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (3*,5*) score=1.2055611610412598\n",
      " init edge (3,6*) score=1.2039191722869873\n",
      " init edge (3,8*) score=1.191990852355957\n",
      " init edge (4*,8) score=1.191209077835083\n",
      " init edge (3,7*) score=1.180071234703064\n",
      " init edge (3,9*) score=1.1685899496078491\n",
      " init edge (3,2*) score=1.1553502082824707\n",
      " init edge (1*,6) score=1.1509897708892822\n",
      " init edge (6,0*) score=1.1210936307907104\n",
      " init loss = 0.00020225885964464396\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps', 'im_poses', 'im_focals']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:48<00:00,  6.23it/s, lr=1.27413e-06 loss=5.88514e-05]\n"
     ]
    }
   ],
   "source": [
    "scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer)\n",
    "loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)\n",
    "\n",
    "imgs = scene.imgs\n",
    "focals = scene.get_focals()\n",
    "poses = scene.get_im_poses()\n",
    "pts3d = scene.get_pts3d()\n",
    "confidence_masks = scene.get_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if pointclouds folder exists\n",
    "#If exists, delete all files in the folder\n",
    "if os.path.exists(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH)):\n",
    "    for file in os.listdir(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH)):\n",
    "        os.remove(\"{DATA_PATH}/pointclouds/{file}\".format(DATA_PATH=DATA_PATH, file=file))\n",
    "        \n",
    "if not os.path.exists(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH)):\n",
    "    os.makedirs(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    pointcloud = pts3d[i].detach().cpu().numpy()\n",
    "    pointcloud = pointcloud.reshape(-1, 3)\n",
    "    color = imgs[i].reshape(-1, 3)\n",
    "    confidence_mask = confidence_masks[i].detach().cpu().numpy()\n",
    "    confidence_mask = confidence_mask.reshape(-1)\n",
    "    \n",
    "    masked_pointcloud = []\n",
    "    masked_color = []\n",
    "\n",
    "    for j in range(len(confidence_mask)):\n",
    "        if confidence_mask[j]:\n",
    "            masked_pointcloud.append(pointcloud[j])\n",
    "            masked_color.append(color[j])\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(masked_pointcloud)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(masked_color)\n",
    "    o3d.io.write_point_cloud(\"{DATA_PATH}/pointclouds/pointcloud{i}.ply\".format(DATA_PATH=DATA_PATH, i=i), pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#Create transform file\n",
    "#TODO: Per frame camera model?\n",
    "transform = {}\n",
    "transform[\"camera_model\"] = \"OPENCV\"\n",
    "\n",
    "averge_focal = focals.sum()/len(focals)\n",
    "transform[\"fl_x\"] = averge_focal.item()\n",
    "transform[\"fl_y\"] = averge_focal.item()\n",
    "\n",
    "#Find size of images\n",
    "img = Image.open(images_array[0])\n",
    "width, height = img.size\n",
    "transform[\"w\"] = width\n",
    "transform[\"h\"] = height\n",
    "transform[\"c_x\"] = width//2\n",
    "transform[\"c_y\"] = height//2\n",
    "\n",
    "transform[\"frames\"] = []\n",
    "\n",
    "for i in range(len(poses)):\n",
    "    if not((confidence_mask[i]==0).all()):\n",
    "        frame = {}\n",
    "        frame[\"file_path\"] = \"/\".join(images_array[i].split(\"/\")[-2:])\n",
    "        frame[\"transform_matrix\"] = poses[i].detach().cpu().numpy().tolist()\n",
    "        frame[\"mask_path\"] = \"/\".join(masks_array[i].split(\"/\")[-2:])\n",
    "        transform[\"frames\"].append(frame)\n",
    "\n",
    "#Save transform file\n",
    "with open(\"{}/transforms.json\".format(DATA_PATH), 'w') as f:\n",
    "    json.dump(transform, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
