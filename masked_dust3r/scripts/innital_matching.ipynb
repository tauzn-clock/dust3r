{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dust3r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/dust3r\")\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import torch\n",
    "\n",
    "from dust3r.inference import inference, inference_with_mask\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "from masked_dust3r.scripts.utils.math import *\n",
    "\n",
    "DATA_PATH = \"/dust3r/masked_dust3r/data/jackal_training_data_0\"\n",
    "IMG_FILE_EXTENSION = \".png\"\n",
    "MASK_FILE_EXTENSION = \".png\"\n",
    "INIT_FRAMES = 15\n",
    "FOCAL_LENGTH = 474\n",
    "\n",
    "device = 'cuda'\n",
    "batch_size = 1\n",
    "schedule = 'cosine'\n",
    "lr = 0.01\n",
    "niter = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading model from checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "model_name = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
    "# you can put the path to a local checkpoint in model_name if needed\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading a list of 50 images\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/0.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/1.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/2.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/3.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/4.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/5.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/6.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/7.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/8.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/9.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/10.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/11.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/12.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/13.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/14.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/15.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/16.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/17.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/18.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/19.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/20.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/21.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/22.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/23.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/24.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/25.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/26.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/27.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/28.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/29.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/30.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/31.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/32.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/33.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/34.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/35.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/36.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/37.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/38.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/39.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/40.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/41.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/42.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/43.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/44.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/45.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/46.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/47.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/48.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/49.png with resolution 1280x720 --> 512x288\n",
      " (Found 50 images)\n"
     ]
    }
   ],
   "source": [
    "images_array = []\n",
    "masks_array = []\n",
    "\n",
    "for i in range(0,50):\n",
    "    images_array.append(os.path.join(DATA_PATH,\"masked_images/{}{}\".format(i,IMG_FILE_EXTENSION)))\n",
    "    masks_array.append(os.path.join(DATA_PATH,\"masks/{}{}\".format(i,MASK_FILE_EXTENSION)))\n",
    "images = load_images(images_array, size=512, verbose=True)\n",
    "\n",
    "masks = []\n",
    "\n",
    "for i in range(len(masks_array)):\n",
    "    mask = Image.open(masks_array[i]).convert('L')\n",
    "    _,_,H,W = images[i][\"img\"].shape\n",
    "    mask = mask.resize((W,H))\n",
    "\n",
    "    mask = np.array(mask)\n",
    "    mask = torch.tensor(mask).to(device)/255\n",
    "    masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Inference with model on 300 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 300/300 [02:05<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "pairs = make_pairs(images, scene_graph='swin', prefilter=None, symmetrize=True)\n",
    "output = inference_with_mask(pairs, model, device, masks, 1.0, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (28*,31*) score=1.2249221801757812\n",
      " init edge (28,30*) score=1.2192926406860352\n",
      " init edge (29*,31) score=1.192214012145996\n",
      " init edge (30,33*) score=1.1820712089538574\n",
      " init edge (29,32*) score=1.1806654930114746\n",
      " init edge (27*,30) score=1.168571949005127\n",
      " init edge (28,26*) score=1.1417688131332397\n",
      " init edge (31,34*) score=1.1411017179489136\n",
      " init edge (32,35*) score=1.1073496341705322\n",
      " init edge (28,25*) score=1.0960865020751953\n",
      " init edge (23*,26) score=1.0948997735977173\n",
      " init edge (36*,34) score=1.0783061981201172\n",
      " init edge (39*,36) score=1.0661605596542358\n",
      " init edge (38*,35) score=1.048963189125061\n",
      " init edge (37*,34) score=1.0472750663757324\n",
      " init edge (20*,23) score=1.1546061038970947\n",
      " init edge (42*,39) score=1.1076107025146484\n",
      " init edge (42,45*) score=1.2190945148468018\n",
      " init edge (17*,20) score=1.2178072929382324\n",
      " init edge (17,19*) score=1.2044249773025513\n",
      " init edge (19,21*) score=1.2003003358840942\n",
      " init edge (43*,45) score=1.192771077156067\n",
      " init edge (17,18*) score=1.1784477233886719\n",
      " init edge (45,46*) score=1.177882194519043\n",
      " init edge (44*,45) score=1.1733111143112183\n",
      " init edge (20,22*) score=1.1565134525299072\n",
      " init edge (45,48*) score=1.1534168720245361\n",
      " init edge (19,16*) score=1.1522958278656006\n",
      " init edge (45,47*) score=1.151941180229187\n",
      " init edge (15*,17) score=1.1412039995193481\n",
      " init edge (40*,43) score=1.140509843826294\n",
      " init edge (42,41*) score=1.1379857063293457\n",
      " init edge (21,24*) score=1.106573224067688\n",
      " init edge (46,49*) score=1.1048341989517212\n",
      " init edge (17,14*) score=1.099827766418457\n",
      " init edge (1*,48) score=1.0863419771194458\n",
      " init edge (15,12*) score=1.0512886047363281\n",
      " init edge (13*,16) score=1.0384485721588135\n",
      " init edge (3*,1) score=1.135309100151062\n",
      " init edge (3,0*) score=1.0831753015518188\n",
      " init edge (3,5*) score=1.2044081687927246\n",
      " init edge (3,6*) score=1.2030466794967651\n",
      " init edge (4*,6) score=1.177977442741394\n",
      " init edge (5,8*) score=1.1761749982833862\n",
      " init edge (4,7*) score=1.1737300157546997\n",
      " init edge (2*,5) score=1.1543610095977783\n",
      " init edge (6,9*) score=1.1486215591430664\n",
      " init edge (7,10*) score=1.1073706150054932\n",
      " init edge (8,11*) score=1.0795457363128662\n",
      " init loss = 0.00022605419508181512\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps.0', 'im_depthmaps.1', 'im_depthmaps.2', 'im_depthmaps.3', 'im_depthmaps.4', 'im_depthmaps.5', 'im_depthmaps.6', 'im_depthmaps.7', 'im_depthmaps.8', 'im_depthmaps.9', 'im_depthmaps.10', 'im_depthmaps.11', 'im_depthmaps.12', 'im_depthmaps.13', 'im_depthmaps.14', 'im_depthmaps.15', 'im_depthmaps.16', 'im_depthmaps.17', 'im_depthmaps.18', 'im_depthmaps.19', 'im_depthmaps.20', 'im_depthmaps.21', 'im_depthmaps.22', 'im_depthmaps.23', 'im_depthmaps.24', 'im_depthmaps.25', 'im_depthmaps.26', 'im_depthmaps.27', 'im_depthmaps.28', 'im_depthmaps.29', 'im_depthmaps.30', 'im_depthmaps.31', 'im_depthmaps.32', 'im_depthmaps.33', 'im_depthmaps.34', 'im_depthmaps.35', 'im_depthmaps.36', 'im_depthmaps.37', 'im_depthmaps.38', 'im_depthmaps.39', 'im_depthmaps.40', 'im_depthmaps.41', 'im_depthmaps.42', 'im_depthmaps.43', 'im_depthmaps.44', 'im_depthmaps.45', 'im_depthmaps.46', 'im_depthmaps.47', 'im_depthmaps.48', 'im_depthmaps.49', 'im_poses.0', 'im_poses.1', 'im_poses.2', 'im_poses.3', 'im_poses.4', 'im_poses.5', 'im_poses.6', 'im_poses.7', 'im_poses.8', 'im_poses.9', 'im_poses.10', 'im_poses.11', 'im_poses.12', 'im_poses.13', 'im_poses.14', 'im_poses.15', 'im_poses.16', 'im_poses.17', 'im_poses.18', 'im_poses.19', 'im_poses.20', 'im_poses.21', 'im_poses.22', 'im_poses.23', 'im_poses.24', 'im_poses.25', 'im_poses.26', 'im_poses.27', 'im_poses.28', 'im_poses.29', 'im_poses.30', 'im_poses.31', 'im_poses.32', 'im_poses.33', 'im_poses.34', 'im_poses.35', 'im_poses.36', 'im_poses.37', 'im_poses.38', 'im_poses.39', 'im_poses.40', 'im_poses.41', 'im_poses.42', 'im_poses.43', 'im_poses.44', 'im_poses.45', 'im_poses.46', 'im_poses.47', 'im_poses.48', 'im_poses.49', 'im_focals.0', 'im_focals.1', 'im_focals.2', 'im_focals.3', 'im_focals.4', 'im_focals.5', 'im_focals.6', 'im_focals.7', 'im_focals.8', 'im_focals.9', 'im_focals.10', 'im_focals.11', 'im_focals.12', 'im_focals.13', 'im_focals.14', 'im_focals.15', 'im_focals.16', 'im_focals.17', 'im_focals.18', 'im_focals.19', 'im_focals.20', 'im_focals.21', 'im_focals.22', 'im_focals.23', 'im_focals.24', 'im_focals.25', 'im_focals.26', 'im_focals.27', 'im_focals.28', 'im_focals.29', 'im_focals.30', 'im_focals.31', 'im_focals.32', 'im_focals.33', 'im_focals.34', 'im_focals.35', 'im_focals.36', 'im_focals.37', 'im_focals.38', 'im_focals.39', 'im_focals.40', 'im_focals.41', 'im_focals.42', 'im_focals.43', 'im_focals.44', 'im_focals.45', 'im_focals.46', 'im_focals.47', 'im_focals.48', 'im_focals.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:48<00:00,  1.04it/s, lr=1.27413e-06 loss=5.28426e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (28*,31*) score=1.2249221801757812\n",
      " init edge (28,30*) score=1.2192926406860352\n",
      " init edge (29*,31) score=1.192214012145996\n",
      " init edge (30,33*) score=1.1820712089538574\n",
      " init edge (29,32*) score=1.1806654930114746\n",
      " init edge (27*,30) score=1.168571949005127\n",
      " init edge (28,26*) score=1.1417688131332397\n",
      " init edge (31,34*) score=1.1411017179489136\n",
      " init edge (32,35*) score=1.1073496341705322\n",
      " init edge (28,25*) score=1.0960865020751953\n",
      " init edge (23*,26) score=1.0948997735977173\n",
      " init edge (36*,34) score=1.0783061981201172\n",
      " init edge (39*,36) score=1.0661605596542358\n",
      " init edge (38*,35) score=1.048963189125061\n",
      " init edge (37*,34) score=1.0472750663757324\n",
      " init edge (20*,23) score=1.1546061038970947\n",
      " init edge (42*,39) score=1.1076107025146484\n",
      " init edge (42,45*) score=1.2190945148468018\n",
      " init edge (17*,20) score=1.2178072929382324\n",
      " init edge (17,19*) score=1.2044249773025513\n",
      " init edge (19,21*) score=1.2003003358840942\n",
      " init edge (43*,45) score=1.192771077156067\n",
      " init edge (17,18*) score=1.1784477233886719\n",
      " init edge (45,46*) score=1.177882194519043\n",
      " init edge (44*,45) score=1.1733111143112183\n",
      " init edge (20,22*) score=1.1565134525299072\n",
      " init edge (45,48*) score=1.1534168720245361\n",
      " init edge (19,16*) score=1.1522958278656006\n",
      " init edge (45,47*) score=1.151941180229187\n",
      " init edge (15*,17) score=1.1412039995193481\n",
      " init edge (40*,43) score=1.140509843826294\n",
      " init edge (42,41*) score=1.1379857063293457\n",
      " init edge (21,24*) score=1.106573224067688\n",
      " init edge (46,49*) score=1.1048341989517212\n",
      " init edge (17,14*) score=1.099827766418457\n",
      " init edge (1*,48) score=1.0863419771194458\n",
      " init edge (15,12*) score=1.0512886047363281\n",
      " init edge (13*,16) score=1.0384485721588135\n",
      " init edge (3*,1) score=1.135309100151062\n",
      " init edge (3,0*) score=1.0831753015518188\n",
      " init edge (3,5*) score=1.2044081687927246\n",
      " init edge (3,6*) score=1.2030466794967651\n",
      " init edge (4*,6) score=1.177977442741394\n",
      " init edge (5,8*) score=1.1761749982833862\n",
      " init edge (4,7*) score=1.1737300157546997\n",
      " init edge (2*,5) score=1.1543610095977783\n",
      " init edge (6,9*) score=1.1486215591430664\n",
      " init edge (7,10*) score=1.1073706150054932\n",
      " init edge (8,11*) score=1.0795457363128662\n",
      " init loss = 9.148576736450195\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps.0', 'im_depthmaps.1', 'im_depthmaps.2', 'im_depthmaps.3', 'im_depthmaps.4', 'im_depthmaps.5', 'im_depthmaps.6', 'im_depthmaps.7', 'im_depthmaps.8', 'im_depthmaps.9', 'im_depthmaps.10', 'im_depthmaps.11', 'im_depthmaps.12', 'im_depthmaps.13', 'im_depthmaps.14', 'im_depthmaps.15', 'im_depthmaps.16', 'im_depthmaps.17', 'im_depthmaps.18', 'im_depthmaps.19', 'im_depthmaps.20', 'im_depthmaps.21', 'im_depthmaps.22', 'im_depthmaps.23', 'im_depthmaps.24', 'im_depthmaps.25', 'im_depthmaps.26', 'im_depthmaps.27', 'im_depthmaps.28', 'im_depthmaps.29', 'im_depthmaps.30', 'im_depthmaps.31', 'im_depthmaps.32', 'im_depthmaps.33', 'im_depthmaps.34', 'im_depthmaps.35', 'im_depthmaps.36', 'im_depthmaps.37', 'im_depthmaps.38', 'im_depthmaps.39', 'im_depthmaps.40', 'im_depthmaps.41', 'im_depthmaps.42', 'im_depthmaps.43', 'im_depthmaps.44', 'im_depthmaps.45', 'im_depthmaps.46', 'im_depthmaps.47', 'im_depthmaps.48', 'im_depthmaps.49', 'im_poses.0', 'im_poses.1', 'im_poses.2', 'im_poses.3', 'im_poses.4', 'im_poses.5', 'im_poses.6', 'im_poses.7', 'im_poses.8', 'im_poses.9', 'im_poses.10', 'im_poses.11', 'im_poses.12', 'im_poses.13', 'im_poses.14', 'im_poses.15', 'im_poses.16', 'im_poses.17', 'im_poses.18', 'im_poses.19', 'im_poses.20', 'im_poses.21', 'im_poses.22', 'im_poses.23', 'im_poses.24', 'im_poses.25', 'im_poses.26', 'im_poses.27', 'im_poses.28', 'im_poses.29', 'im_poses.30', 'im_poses.31', 'im_poses.32', 'im_poses.33', 'im_poses.34', 'im_poses.35', 'im_poses.36', 'im_poses.37', 'im_poses.38', 'im_poses.39', 'im_poses.40', 'im_poses.41', 'im_poses.42', 'im_poses.43', 'im_poses.44', 'im_poses.45', 'im_poses.46', 'im_poses.47', 'im_poses.48', 'im_poses.49', 'im_focals.0', 'im_focals.1', 'im_focals.2', 'im_focals.3', 'im_focals.4', 'im_focals.5', 'im_focals.6', 'im_focals.7', 'im_focals.8', 'im_focals.9', 'im_focals.10', 'im_focals.11', 'im_focals.12', 'im_focals.13', 'im_focals.14', 'im_focals.15', 'im_focals.16', 'im_focals.17', 'im_focals.18', 'im_focals.19', 'im_focals.20', 'im_focals.21', 'im_focals.22', 'im_focals.23', 'im_focals.24', 'im_focals.25', 'im_focals.26', 'im_focals.27', 'im_focals.28', 'im_focals.29', 'im_focals.30', 'im_focals.31', 'im_focals.32', 'im_focals.33', 'im_focals.34', 'im_focals.35', 'im_focals.36', 'im_focals.37', 'im_focals.38', 'im_focals.39', 'im_focals.40', 'im_focals.41', 'im_focals.42', 'im_focals.43', 'im_focals.44', 'im_focals.45', 'im_focals.46', 'im_focals.47', 'im_focals.48', 'im_focals.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:21<00:00,  1.07s/it, lr=1.27413e-06 loss=7.02729]\n"
     ]
    }
   ],
   "source": [
    "init_scene = global_aligner(output, device=device, mode=GlobalAlignerMode.ModularPointCloudOptimizer)\n",
    "loss = init_scene.compute_global_alignment(init=\"mst\", niter=niter, schedule='cosine', lr=lr)\n",
    "\n",
    "scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PlanePointCloudOptimizer, \n",
    "                       weight_focal = 1, \n",
    "                       weight_z = 0.1, \n",
    "                       weight_rot = 0.1, \n",
    "                       weight_trans_smoothness = 0.001,\n",
    "                       weight_rot_smoothness = 0.001)\n",
    "scene.im_poses = calculate_new_params(init_scene.im_poses,device)\n",
    "scene.im_focals = init_scene.im_focals\n",
    "loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = scene.imgs\n",
    "focals = scene.get_focals()\n",
    "poses = scene.get_im_poses()\n",
    "pts3d = scene.get_pts3d()\n",
    "confidence_masks = scene.get_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] Write PLY failed: point cloud has 0 points.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Write PLY failed: point cloud has 0 points.\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "#Check if pointclouds folder exists\n",
    "#If exists, delete all files in the folder\n",
    "if os.path.exists(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH)):\n",
    "    for file in os.listdir(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH)):\n",
    "        os.remove(\"{DATA_PATH}/pointclouds/{file}\".format(DATA_PATH=DATA_PATH, file=file))\n",
    "        \n",
    "if not os.path.exists(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH)):\n",
    "    os.makedirs(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    pointcloud = pts3d[i].detach().cpu().numpy()\n",
    "    pointcloud = pointcloud.reshape(-1, 3)\n",
    "    color = imgs[i].reshape(-1, 3)\n",
    "    confidence_mask = confidence_masks[i].detach().cpu().numpy()\n",
    "    confidence_mask = confidence_mask.reshape(-1)\n",
    "    \n",
    "    masked_pointcloud = []\n",
    "    masked_color = []\n",
    "\n",
    "    for j in range(len(confidence_mask)):\n",
    "        if confidence_mask[j]:\n",
    "            masked_pointcloud.append(pointcloud[j])\n",
    "            masked_color.append(color[j])\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(masked_pointcloud)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(masked_color)\n",
    "    o3d.io.write_point_cloud(\"{DATA_PATH}/pointclouds/pointcloud{i}.ply\".format(DATA_PATH=DATA_PATH, i=i), pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#Create transform file\n",
    "#TODO: Per frame camera model?\n",
    "transform = {}\n",
    "transform[\"camera_model\"] = \"OPENCV\"\n",
    "\n",
    "averge_focal = focals.sum()/len(focals)\n",
    "transform[\"fl_x\"] = averge_focal.item()\n",
    "transform[\"fl_y\"] = averge_focal.item()\n",
    "\n",
    "#Find size of images\n",
    "img = Image.open(images_array[0])\n",
    "width, height = img.size\n",
    "transform[\"w\"] = width\n",
    "transform[\"h\"] = height\n",
    "transform[\"cx\"] = width//2\n",
    "transform[\"cy\"] = height//2\n",
    "\n",
    "transform[\"frames\"] = []\n",
    "\n",
    "for i in range(len(poses)):\n",
    "    if not((confidence_masks[i]==0).all()):\n",
    "        frame = {}\n",
    "        frame[\"file_path\"] = \"/\".join(images_array[i].split(\"/\")[-2:])\n",
    "        frame[\"transform_matrix\"] = poses[i].detach().cpu().numpy().tolist()\n",
    "        frame[\"mask_path\"] = \"/\".join(masks_array[i].split(\"/\")[-2:])\n",
    "        transform[\"frames\"].append(frame)\n",
    "\n",
    "#Save transform file\n",
    "with open(\"{}/transforms.json\".format(DATA_PATH), 'w') as f:\n",
    "    json.dump(transform, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
