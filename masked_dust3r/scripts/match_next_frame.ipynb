{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dust3r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/dust3r\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import json\n",
    "import open3d as o3d\n",
    "\n",
    "from dust3r.inference import inference_with_mask, create_gaussian_kernel\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "from dust3r.cloud_opt.base_opt import global_alignment_loop\n",
    "from masked_dust3r.scripts.utils.math import *\n",
    "from masked_dust3r.scripts.utils.image import *\n",
    "\n",
    "\n",
    "DATA_PATH = \"/dust3r/masked_dust3r/data/jackal_training_data_0\"\n",
    "IMG_FILE_EXTENSION = \".png\"\n",
    "MASK_FILE_EXTENSION = \".png\"\n",
    "\n",
    "INIT_FRAMES = 25\n",
    "NEW_FRAMES = 5\n",
    "PREVIOUS_FRAMES = 10\n",
    "TOTAL_FRAMES = 300\n",
    "\n",
    "INIT_WEIGHT_FOCAL = 0.1 * 0\n",
    "INIT_WEIGHT_Z = 0.1 \n",
    "INIT_WEIGHT_ROT = 0.01\n",
    "INIT_WEIGHT_TRANS_SMOOTHNESS = 0.0001 \n",
    "INIT_WEIGHT_ROT_SMOOTHNESS = 0.001 * 0\n",
    "\n",
    "NEW_WEIGHT_FOCAL = 0.1 * 0\n",
    "NEW_WEIGHT_Z = 0.1\n",
    "NEW_WEIGHT_ROT = 0.01\n",
    "NEW_WEIGHT_TRANS_SMOOTHNESS = 0.0001\n",
    "NEW_WEIGHT_ROT_SMOOTHNESS = 0.00001 * 0\n",
    "\n",
    "USE_COMMON_INTRINSICS = False\n",
    "RESCALE_FACTOR  = 1280/512\n",
    "\n",
    "device = 'cuda'\n",
    "batch_size = 1\n",
    "schedule = 'cosine'\n",
    "lr = 0.01\n",
    "niter = 300 \n",
    "\n",
    "\n",
    "with open(f\"{DATA_PATH}/transforms_init.json\") as f:\n",
    "    transforms = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "GAUSSIAN_SIGMA = 51.0\n",
    "SIZE = int(GAUSSIAN_SIGMA * 3)\n",
    "\n",
    "kernel = create_gaussian_kernel(SIZE, GAUSSIAN_SIGMA).to(device)\n",
    "\n",
    "SIZE = 11\n",
    "kernel = torch.ones(SIZE, SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading model from checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "model_name = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
    "# you can put the path to a local checkpoint in model_name if needed\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refering to masked_images/15.png...\n",
      "Refering to masked_images/16.png...\n",
      "Refering to masked_images/17.png...\n",
      "Refering to masked_images/18.png...\n",
      "Refering to masked_images/19.png...\n",
      "Refering to masked_images/20.png...\n",
      "Refering to masked_images/21.png...\n",
      "Refering to masked_images/22.png...\n",
      "Refering to masked_images/23.png...\n",
      "Refering to masked_images/24.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/25.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/26.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/27.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/28.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/29.png...\n",
      ">> Loading a list of 15 images\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/15.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/16.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/17.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/18.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/19.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/20.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/21.png with resolution 1280x720 --> 512x288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/22.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/23.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/24.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/25.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/26.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/27.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/28.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/29.png with resolution 1280x720 --> 512x288\n",
      " (Found 15 images)\n"
     ]
    }
   ],
   "source": [
    "for start_frame_index in range(INIT_FRAMES, TOTAL_FRAMES, NEW_FRAMES):\n",
    "    images_array = []\n",
    "    masks_array = []\n",
    "\n",
    "    if USE_COMMON_INTRINSICS:\n",
    "        preset_focal = [transforms[\"fl_x\"]/RESCALE_FACTOR for _ in range(PREVIOUS_FRAMES+NEW_FRAMES)]\n",
    "    else:\n",
    "        preset_focal = []\n",
    "\n",
    "    preset_pose = []\n",
    "    preset_mask = [True for _ in range(PREVIOUS_FRAMES+NEW_FRAMES)]\n",
    "    preset_mask[PREVIOUS_FRAMES:] = [False for _ in range(NEW_FRAMES)]\n",
    "\n",
    "    for i in range(len(transforms[\"frames\"])-PREVIOUS_FRAMES, len(transforms[\"frames\"])):\n",
    "        images_array.append(os.path.join(DATA_PATH,transforms[\"frames\"][i][\"file_path\"]))\n",
    "        masks_array.append(os.path.join(DATA_PATH,transforms[\"frames\"][i][\"mask_path\"]))\n",
    "        preset_pose.append(np.array(transforms[\"frames\"][i][\"transform_matrix\"]))\n",
    "        if not USE_COMMON_INTRINSICS:\n",
    "            preset_focal.append(transforms[\"frames\"][i][\"fl_x\"]/RESCALE_FACTOR)\n",
    "        print(\"Refering to {}...\".format(transforms[\"frames\"][i][\"file_path\"]))\n",
    "\n",
    "    last_known_pose = preset_pose[-1]\n",
    "    last_known_focal= preset_focal[-1]\n",
    "\n",
    "    for i in range(start_frame_index, start_frame_index + NEW_FRAMES):\n",
    "        images_array.append(os.path.join(DATA_PATH,\"masked_images/{}{}\".format(i,IMG_FILE_EXTENSION)))\n",
    "        masks_array.append(os.path.join(DATA_PATH,\"masks/{}{}\".format(i,MASK_FILE_EXTENSION)))\n",
    "        preset_pose.append(last_known_pose)\n",
    "        if not USE_COMMON_INTRINSICS: preset_focal.append(last_known_focal)\n",
    "        print(\"Estimating for {}...\".format(os.path.join(DATA_PATH,\"masked_images/{}{}\".format(i,IMG_FILE_EXTENSION))))\n",
    "\n",
    "    images = load_images(images_array, size=512, verbose=True)\n",
    "    _,_,H,W = images[0][\"img\"].shape\n",
    "    masks = load_masks(masks_array, H, W, device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Inference with model on 150 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:46<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "pairs = make_pairs(images, scene_graph='swin-{}'.format(5), prefilter=None, symmetrize=True)\n",
    "output = inference_with_mask(pairs, model, device, masks, kernel, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.4003,  0.7331, -0.6836, -1.2265, -0.6846, -0.0236, -1.6716],\n",
      "       device='cuda:0', requires_grad=True)\n",
      " (setting focal #0 = 459.58935546875)\n",
      " (setting focal #1 = 440.4442138671875)\n",
      " (setting focal #2 = 528.2886962890625)\n",
      " (setting focal #3 = 492.1719970703125)\n",
      " (setting focal #4 = 516.344970703125)\n",
      " (setting focal #5 = 506.750732421875)\n",
      " (setting focal #6 = 498.5870361328125)\n",
      " (setting focal #7 = 438.8687438964844)\n",
      " (setting focal #8 = 449.9277648925781)\n",
      " (setting focal #9 = 523.98876953125)\n",
      " (setting pose #0 = [-0.01574595  0.00103616  0.00583295])\n",
      " (setting pose #1 = [-0.00787305  0.0020128   0.00599961])\n",
      " (setting pose #2 = [0. 0. 0.])\n",
      " (setting pose #3 = [ 0.02126615 -0.00295147  0.00213417])\n",
      " (setting pose #4 = [ 0.04253045 -0.01279747  0.00425808])\n",
      " (setting pose #5 = [ 0.06041355 -0.02349862  0.00590006])\n",
      " (setting pose #6 = [ 0.07402549 -0.03513174  0.00733913])\n",
      " (setting pose #7 = [ 0.08753103 -0.04698689  0.00875222])\n",
      " (setting pose #8 = [ 0.09699547 -0.06164459  0.00619636])\n",
      " (setting pose #9 = [ 0.10238454 -0.07633315  0.00210309])\n",
      " init edge (2*,5*) score=1.2195663452148438\n",
      " init edge (2,4*) score=1.2064969539642334\n",
      " init edge (4,6*) score=1.2022987604141235\n",
      " init edge (2,3*) score=1.1798925399780273\n",
      " init edge (4,14*) score=1.1675578355789185\n",
      " init edge (5,1*) score=1.1648982763290405\n",
      " init edge (5,7*) score=1.158280372619629\n",
      " init edge (5,8*) score=1.1558665037155151\n",
      " init edge (4,0*) score=1.1521621942520142\n",
      " init edge (5,10*) score=1.1067560911178589\n",
      " init edge (14,13*) score=1.1720057725906372\n",
      " init edge (13,12*) score=1.1660469770431519\n",
      " init edge (13,11*) score=1.1431971788406372\n",
      " init edge (13,9*) score=1.1184762716293335\n",
      " init loss = 131.27354431152344\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps.0', 'im_depthmaps.1', 'im_depthmaps.2', 'im_depthmaps.3', 'im_depthmaps.4', 'im_depthmaps.5', 'im_depthmaps.6', 'im_depthmaps.7', 'im_depthmaps.8', 'im_depthmaps.9', 'im_depthmaps.10', 'im_depthmaps.11', 'im_depthmaps.12', 'im_depthmaps.13', 'im_depthmaps.14', 'im_poses.10', 'im_poses.11', 'im_poses.12', 'im_poses.13', 'im_poses.14', 'im_focals.10', 'im_focals.11', 'im_focals.12', 'im_focals.13', 'im_focals.14']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 50/300 [00:30<02:31,  1.66it/s, lr=0.00935613 loss=107.667]"
     ]
    }
   ],
   "source": [
    "scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PlanePointCloudOptimizer, \n",
    "                        weight_focal = NEW_WEIGHT_FOCAL,\n",
    "                        weight_z = NEW_WEIGHT_Z ,\n",
    "                        weight_rot = NEW_WEIGHT_ROT ,\n",
    "                        weight_trans_smoothness = NEW_WEIGHT_TRANS_SMOOTHNESS,\n",
    "                        weight_rot_smoothness = NEW_WEIGHT_ROT_SMOOTHNESS)\n",
    "print(scene.im_poses[-1])\n",
    "if USE_COMMON_INTRINSICS :\n",
    "    scene.preset_focal(preset_focal, [True for _ in range(PREVIOUS_FRAMES+NEW_FRAMES)])\n",
    "else:\n",
    "    scene.preset_focal(preset_focal, preset_mask)\n",
    "scene.preset_pose(preset_pose, preset_mask)\n",
    "loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)\n",
    "print(scene.im_poses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9995, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "all_focal = torch.stack(list(scene.im_focals))\n",
    "all_poses = torch.stack(list(scene.im_poses))\n",
    "Q = all_poses[:,:4]\n",
    "Q = torch.nn.functional.normalize(Q, p=2, dim=1)\n",
    "T = signed_expm1(all_poses[:,4:7])\n",
    "tf = roma.RigidUnitQuat(Q, T).normalize()#.to_homogeneous()#.inverse()\n",
    "tf_inv = tf.inverse()\n",
    "\n",
    "off_z_axis = torch.tensor([]).to(device)\n",
    "\n",
    "#print(tf.linear[:,3])\n",
    "\n",
    "cnt = 0\n",
    "for e, (i, j) in enumerate(scene.edges):\n",
    "    cnt+=1\n",
    "    #print(torch.nn.functional.normalize((tf_inv[i] @ tf[j]).linear[:3],p=2, dim=0, eps=1e-12,))\n",
    "    print(torch.nn.functional.normalize((tf[j] @ tf_inv[i]).linear[:3],p=2, dim=0, eps=1e-12)[2].abs())\n",
    "    #off_z_axis = torch.cat((off_z_axis, 1-torch.nn.functional.normalize((tf[j] @ tf_inv[i]).linear[:3],p=2, dim=0, eps=1e-12)[2].abs().unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = scene.imgs\n",
    "focals = scene.get_focals()\n",
    "poses = scene.get_im_poses()\n",
    "pts3d = scene.get_pts3d()\n",
    "confidence_masks = scene.get_masks()\n",
    "intrinsics = scene.get_intrinsics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if pointclouds folder exists\n",
    "#If exists, delete all files in the folder\n",
    "if os.path.exists(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH)):\n",
    "    for file in os.listdir(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH)):\n",
    "        os.remove(\"{DATA_PATH}/pointclouds/{file}\".format(DATA_PATH=DATA_PATH, file=file))\n",
    "        \n",
    "if not os.path.exists(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH)):\n",
    "    os.makedirs(\"{DATA_PATH}/pointclouds\".format(DATA_PATH=DATA_PATH))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    pointcloud = pts3d[i].detach().cpu().numpy()\n",
    "    pointcloud = pointcloud.reshape(-1, 3)\n",
    "    color = imgs[i].reshape(-1, 3)\n",
    "    confidence_mask = confidence_masks[i].detach().cpu().numpy()\n",
    "    confidence_mask = confidence_mask.reshape(-1)\n",
    "    \n",
    "    masked_pointcloud = []\n",
    "    masked_color = []\n",
    "\n",
    "    for j in range(len(confidence_mask)):\n",
    "        if confidence_mask[j]:\n",
    "            masked_pointcloud.append(pointcloud[j])\n",
    "            masked_color.append(color[j])\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(masked_pointcloud)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(masked_color)\n",
    "    o3d.io.write_point_cloud(\"{DATA_PATH}/pointclouds/pointcloud{i}.ply\".format(DATA_PATH=DATA_PATH, i=i), pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENGL = np.array([[1, 0, 0, 0],\n",
    "                    [0, -1, 0, 0],\n",
    "                    [0, 0, -1, 0],\n",
    "                    [0, 0, 0, 1]])\n",
    "\n",
    "\n",
    "for i in range(PREVIOUS_FRAMES, PREVIOUS_FRAMES+NEW_FRAMES):\n",
    "    if not((confidence_masks[i]==0).all()):\n",
    "        frame = {}\n",
    "        frame[\"file_path\"] = \"/\".join(images_array[i].split(\"/\")[-2:])\n",
    "        #frame[\"transform_matrix\"] = np.linalg.inv(poses[i].detach().cpu().numpy()).tolist()\n",
    "        frame[\"transform_matrix\"] = np.dot(poses[i].detach().cpu().numpy(),OPENGL).tolist()\n",
    "        frame[\"mask_path\"] = \"/\".join(masks_array[i].split(\"/\")[-2:])\n",
    "        transforms[\"frames\"].append(frame)\n",
    "        \n",
    "        if not USE_COMMON_INTRINSICS:\n",
    "            frame[\"fl_x\"] = intrinsics[i,0,0].item() * RESCALE_FACTOR\n",
    "            frame[\"fl_y\"] = intrinsics[i,1,1].item() * RESCALE_FACTOR\n",
    "            frame[\"cx\"] = intrinsics[i,0,2].item() * RESCALE_FACTOR\n",
    "            frame[\"cy\"] = intrinsics[i,1,2].item() * RESCALE_FACTOR\n",
    "            img = Image.open(images_array[i])\n",
    "            width, height = img.size\n",
    "            transforms[\"w\"] = width \n",
    "            transforms[\"h\"] = height \n",
    "\n",
    "with open(f\"{DATA_PATH}/transforms.json\", \"w\") as f:\n",
    "    json.dump(transforms, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
