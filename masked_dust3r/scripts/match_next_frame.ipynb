{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dust3r\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    }
   ],
   "source": [
    "#!/bin/python3 python3.10\n",
    "\n",
    "import os\n",
    "#Set directory to dust3r\n",
    "os.chdir(\"/dust3r\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import torch\n",
    "import json\n",
    "from masked_dust3r.scripts.utils.image import *\n",
    "from masked_dust3r.scripts.utils.constraint import *\n",
    "\n",
    "from dust3r.inference import inference_with_mask\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "\n",
    "DATA_PATH = \"/dust3r/masked_dust3r/data/jackal_training_data_0\"\n",
    "IMG_FILE_EXTENSION = \".png\"\n",
    "MASK_FILE_EXTENSION = \".png\"\n",
    "GAUSSIAN_SIGMA = 3.0\n",
    "INIT_FRAMES = 10\n",
    "RECURRING_FRAMES = 5\n",
    "TOTAL_IMGS = 11\n",
    "\n",
    "IS_FOCAL_FIXED = False\n",
    "IS_BEST_FIT_PLANE = True\n",
    "IS_ZERO_Z = True\n",
    "FOCAL_LENGTH = 4.74\n",
    "\n",
    "device = 'cuda'\n",
    "batch_size = 1\n",
    "schedule = 'cosine'\n",
    "lr = 0.01\n",
    "niter = 300\n",
    "\n",
    "with open(f\"{DATA_PATH}/transforms.json\") as f:\n",
    "    transforms = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading model from checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "model_name = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
    "# you can put the path to a local checkpoint in model_name if needed\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at frame 10...\n",
      "Using masked_images/45.png...\n",
      "Using masked_images/46.png...\n",
      "Using masked_images/47.png...\n",
      "Using masked_images/48.png...\n",
      "Using masked_images/49.png...\n",
      ">> Loading a list of 6 images\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/10.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/45.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/46.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/47.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/48.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/49.png with resolution 1280x720 --> 512x288\n",
      " (Found 6 images)\n"
     ]
    }
   ],
   "source": [
    "new_img_index = 10\n",
    "print(\"Looking at frame {}...\".format(new_img_index))\n",
    "images_array = []\n",
    "masks_array = []\n",
    "\n",
    "preset_focal = [transforms[\"fl_x\"] for _ in range(RECURRING_FRAMES+1)]\n",
    "preset_pose = []\n",
    "preset_mask = [True for _ in range(RECURRING_FRAMES+1)]\n",
    "preset_mask[0] = False\n",
    "\n",
    "images_array.append(os.path.join(DATA_PATH,\"masked_images/{}{}\".format(new_img_index,IMG_FILE_EXTENSION)))\n",
    "masks_array.append(os.path.join(DATA_PATH,\"masks/{}{}\".format(new_img_index,MASK_FILE_EXTENSION)))\n",
    "preset_pose.append(np.eye(4))\n",
    "\n",
    "for i in range(-RECURRING_FRAMES,0):\n",
    "    images_array.append(os.path.join(DATA_PATH,transforms[\"frames\"][i][\"file_path\"]))\n",
    "    masks_array.append(os.path.join(DATA_PATH,transforms[\"frames\"][i][\"mask_path\"]))\n",
    "    preset_pose.append(np.array(transforms[\"frames\"][i][\"transform_matrix\"]))\n",
    "    print(\"Using {}...\".format(transforms[\"frames\"][i][\"file_path\"]))\n",
    "preset_pose[0] = preset_pose[-1]\n",
    "\n",
    "images = load_images(images_array, size=512, verbose=True)\n",
    "_,_,H,W = images[0][\"img\"].shape\n",
    "masks = load_masks(masks_array, H, W, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Inference with model on 10 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "pairs = make_pairs(images, scene_graph='oneref-0', prefilter=None, symmetrize=True)\n",
    "output = inference_with_mask(pairs, model, device, masks, GAUSSIAN_SIGMA, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (setting focal #0 = 481.6600341796875)\n",
      " (setting focal #1 = 481.6600341796875)\n",
      " (setting focal #2 = 481.6600341796875)\n",
      " (setting focal #3 = 481.6600341796875)\n",
      " (setting focal #4 = 481.6600341796875)\n",
      " (setting focal #5 = 481.6600341796875)\n",
      " (setting pose #1 = [ 0.12649737 -0.3028121   0.27151915])\n",
      " (setting pose #2 = [ 0.1903113  -0.24278216  0.23373555])\n",
      " (setting pose #3 = [ 0.1713087  -0.25071609  0.24321499])\n",
      " (setting pose #4 = [ 0.15801997 -0.26054999  0.26193309])\n",
      " (setting pose #5 = [ 0.14215846 -0.27457073  0.27348831])\n"
     ]
    }
   ],
   "source": [
    "scene = global_aligner(output, device=device, mode=GlobalAlignerMode.ModularPointCloudOptimizer)\n",
    "scene.preset_focal(preset_focal, [True for _ in range(RECURRING_FRAMES+1)])\n",
    "scene.preset_pose(preset_pose, preset_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0130,  0.6145,  0.7229, -0.3157,  0.1191, -0.2645,  0.2402],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8004,  0.4724, -0.3692,  0.1265],\n",
      "        [-0.4404, -0.0454,  0.8967, -0.3028],\n",
      "        [ 0.4068,  0.8802,  0.2443,  0.2715],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(scene.im_poses[1])\n",
    "print(scene.get_im_poses()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_expm1(x):\n",
    "    sign = torch.sign(x)\n",
    "    return sign * torch.expm1(torch.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0360,  0.7223, -0.3021, -0.6396,  0.1253, -0.2360,  0.2437],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(scene.im_poses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([[[-0.1980, -0.3268, -0.9241,  0.1335],\n",
      "         [ 0.4284,  0.8191, -0.3815, -0.2661],\n",
      "         [ 0.8816, -0.4714, -0.0222,  0.2760],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.8004,  0.4724, -0.3692,  0.1265],\n",
      "         [-0.4404, -0.0454,  0.8967, -0.3028],\n",
      "         [ 0.4068,  0.8802,  0.2443,  0.2715],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.4616,  0.6809, -0.5686,  0.1903],\n",
      "         [-0.6449,  0.1825,  0.7421, -0.2428],\n",
      "         [ 0.6091,  0.7093,  0.3549,  0.2337],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.5520,  0.6477, -0.5252,  0.1713],\n",
      "         [-0.6134,  0.1112,  0.7819, -0.2507],\n",
      "         [ 0.5648,  0.7538,  0.3359,  0.2432],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.6415,  0.5865, -0.4944,  0.1580],\n",
      "         [-0.5625,  0.0785,  0.8231, -0.2605],\n",
      "         [ 0.5216,  0.8061,  0.2796,  0.2619],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.7260,  0.5258, -0.4432,  0.1422],\n",
      "         [-0.5046,  0.0305,  0.8628, -0.2746],\n",
      "         [ 0.4672,  0.8501,  0.2431,  0.2735],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "for param, pose in zip(scene.im_poses, scene.get_im_poses()):\n",
    "    print(pose[0,3]/signed_expm1(param[4]))\n",
    "    print(pose[1,3]/signed_expm1(param[5]))\n",
    "    print(pose[2,3]/signed_expm1(param[6]))\n",
    "\n",
    "im_pose =  scene.get_im_poses()\n",
    "print(im_pose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.7878,  0.1551, -1.0806,  0.6953, -1.3535,  1.3133,  0.7201],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0130,  0.6145,  0.7229, -0.3157,  0.1191, -0.2645,  0.2402],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([ 0.0158,  0.5677,  0.6392, -0.5186,  0.1742, -0.2174,  0.2100],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([ 0.0148,  0.5760,  0.6665, -0.4730,  0.1581, -0.2237,  0.2177],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([ 0.0100,  0.6001,  0.6787, -0.4232,  0.1467, -0.2315,  0.2326],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([ 0.0086,  0.6151,  0.6962, -0.3700,  0.1329, -0.2426,  0.2418],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in scene.im_poses:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (0*,1*) score=1.0644137859344482\n",
      " init edge (2*,0) score=1.0251412391662598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (5*,0) score=1.0133864879608154\n",
      " init edge (3*,0) score=1.00983464717865\n",
      " init edge (4*,0) score=1.0085440874099731\n",
      " init loss = 0.000306908565107733\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps.0', 'im_depthmaps.1', 'im_depthmaps.2', 'im_depthmaps.3', 'im_depthmaps.4', 'im_depthmaps.5', 'im_poses.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:19<00:00, 15.28it/s, lr=1.27413e-06 loss=2.0939e-05] \n"
     ]
    }
   ],
   "source": [
    "loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0360,  0.7223, -0.3021, -0.6396,  0.1253, -0.2360,  0.2437],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0130,  0.6145,  0.7229, -0.3157,  0.1191, -0.2645,  0.2402],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([ 0.0158,  0.5677,  0.6392, -0.5186,  0.1742, -0.2174,  0.2100],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([ 0.0148,  0.5760,  0.6665, -0.4730,  0.1581, -0.2237,  0.2177],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([ 0.0100,  0.6001,  0.6787, -0.4232,  0.1467, -0.2315,  0.2326],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([ 0.0086,  0.6151,  0.6962, -0.3700,  0.1329, -0.2426,  0.2418],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in scene.im_poses:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1980, -0.3268, -0.9241,  0.1335],\n",
      "         [ 0.4284,  0.8191, -0.3815, -0.2661],\n",
      "         [ 0.8816, -0.4714, -0.0222,  0.2760],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.8004,  0.4724, -0.3692,  0.1265],\n",
      "         [-0.4404, -0.0454,  0.8967, -0.3028],\n",
      "         [ 0.4068,  0.8802,  0.2443,  0.2715],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.4616,  0.6809, -0.5686,  0.1903],\n",
      "         [-0.6449,  0.1825,  0.7421, -0.2428],\n",
      "         [ 0.6091,  0.7093,  0.3549,  0.2337],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.5520,  0.6477, -0.5252,  0.1713],\n",
      "         [-0.6134,  0.1112,  0.7819, -0.2507],\n",
      "         [ 0.5648,  0.7538,  0.3359,  0.2432],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.6415,  0.5865, -0.4944,  0.1580],\n",
      "         [-0.5625,  0.0785,  0.8231, -0.2605],\n",
      "         [ 0.5216,  0.8061,  0.2796,  0.2619],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "        [[-0.7260,  0.5258, -0.4432,  0.1422],\n",
      "         [-0.5046,  0.0305,  0.8628, -0.2746],\n",
      "         [ 0.4672,  0.8501,  0.2431,  0.2735],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "im_pose =  scene.get_im_poses()\n",
    "print(im_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgs = scene.imgs\n",
    "focals = scene.get_focals()\n",
    "poses = scene.get_im_poses()\n",
    "pts3d = scene.get_pts3d()\n",
    "confidence_masks = scene.get_masks()\n",
    "\n",
    "if (confidence_masks[0]!=0).all():\n",
    "    print(\"No confidence in Frame {}\".format(new_img_index))       \n",
    "    pass\n",
    "\n",
    "new_tf = poses[0].detach().cpu().numpy().tolist()\n",
    "if abs(new_tf[2][3]) > 0.1:\n",
    "    pass\n",
    "new_tf[2][3] = 0\n",
    "\n",
    "new_frame = {\n",
    "    \"file_path\" : \"/\".join(images_array[0].split(\"/\")[-2:]),\n",
    "    \"transform_matrix\" : new_tf,\n",
    "    \"mask_path\" : \"/\".join(masks_array[0].split(\"/\")[-2:])\n",
    "}\n",
    "#transforms[\"frames\"].append(new_frame)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
