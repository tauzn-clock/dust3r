{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dust3r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/dust3r\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from dust3r.inference import inference_with_mask\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "from masked_dust3r.scripts.utils.math import *\n",
    "from masked_dust3r.scripts.utils.image import *\n",
    "\n",
    "\n",
    "DATA_PATH = \"/dust3r/masked_dust3r/data/jackal_training_data_0\"\n",
    "IMG_FILE_EXTENSION = \".png\"\n",
    "MASK_FILE_EXTENSION = \".png\"\n",
    "GAUSSIAN_SIGMA = 1.0\n",
    "INIT_FRAMES = 50\n",
    "NEW_FRAMES = 10\n",
    "PREVIOUS_FRAMES = 10\n",
    "TOTAL_FRAMES = 60\n",
    "\n",
    "IS_FOCAL_FIXED = True\n",
    "FOCAL_LENGTH = 4.74\n",
    "\n",
    "device = 'cuda'\n",
    "batch_size = 1\n",
    "schedule = 'cosine'\n",
    "lr = 0.01\n",
    "niter = 300\n",
    "\n",
    "with open(f\"{DATA_PATH}/transforms.json\") as f:\n",
    "    transforms = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading model from checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
      "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "model_name = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
    "# you can put the path to a local checkpoint in model_name if needed\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refering to masked_images/50.png...\n",
      "Refering to masked_images/51.png...\n",
      "Refering to masked_images/52.png...\n",
      "Refering to masked_images/53.png...\n",
      "Refering to masked_images/54.png...\n",
      "Refering to masked_images/55.png...\n",
      "Refering to masked_images/56.png...\n",
      "Refering to masked_images/57.png...\n",
      "Refering to masked_images/58.png...\n",
      "Refering to masked_images/59.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/50.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/51.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/52.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/53.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/54.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/55.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/56.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/57.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/58.png...\n",
      "Estimating for /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/59.png...\n",
      ">> Loading a list of 20 images\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/50.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/51.png with resolution 1280x720 --> 512x288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/52.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/53.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/54.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/55.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/56.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/57.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/58.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/59.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/50.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/51.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/52.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/53.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/54.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/55.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/56.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/57.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/58.png with resolution 1280x720 --> 512x288\n",
      " - adding /dust3r/masked_dust3r/data/jackal_training_data_0/masked_images/59.png with resolution 1280x720 --> 512x288\n",
      " (Found 20 images)\n"
     ]
    }
   ],
   "source": [
    "for start_frame_index in range(INIT_FRAMES, TOTAL_FRAMES, NEW_FRAMES):\n",
    "    images_array = []\n",
    "    masks_array = []\n",
    "\n",
    "    preset_focal = [transforms[\"fl_x\"] for _ in range(PREVIOUS_FRAMES+NEW_FRAMES)]\n",
    "    preset_pose = []\n",
    "    preset_mask = [True for _ in range(PREVIOUS_FRAMES+NEW_FRAMES)]\n",
    "    preset_mask[PREVIOUS_FRAMES:] = [False for _ in range(NEW_FRAMES)]\n",
    "\n",
    "    for i in range(len(transforms[\"frames\"])-PREVIOUS_FRAMES, len(transforms[\"frames\"])):\n",
    "        images_array.append(os.path.join(DATA_PATH,transforms[\"frames\"][i][\"file_path\"]))\n",
    "        masks_array.append(os.path.join(DATA_PATH,transforms[\"frames\"][i][\"mask_path\"]))\n",
    "        preset_pose.append(np.array(transforms[\"frames\"][i][\"transform_matrix\"]))\n",
    "        print(\"Refering to {}...\".format(transforms[\"frames\"][i][\"file_path\"]))\n",
    "\n",
    "    last_known_pose = preset_pose[-1]\n",
    "\n",
    "    for i in range(start_frame_index, start_frame_index + NEW_FRAMES):\n",
    "        images_array.append(os.path.join(DATA_PATH,\"masked_images/{}{}\".format(i,IMG_FILE_EXTENSION)))\n",
    "        masks_array.append(os.path.join(DATA_PATH,\"masks/{}{}\".format(i,MASK_FILE_EXTENSION)))\n",
    "        preset_pose.append(last_known_pose)\n",
    "        print(\"Estimating for {}...\".format(os.path.join(DATA_PATH,\"masked_images/{}{}\".format(i,IMG_FILE_EXTENSION))))\n",
    "\n",
    "    images = load_images(images_array, size=512, verbose=True)\n",
    "    _,_,H,W = images[0][\"img\"].shape\n",
    "    masks = load_masks(masks_array, H, W, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Inference with model on 380 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/380 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 380/380 [02:36<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "pairs = make_pairs(images, scene_graph='swin-{}'.format(PREVIOUS_FRAMES), prefilter=None, symmetrize=True)\n",
    "output = inference_with_mask(pairs, model, device, masks, GAUSSIAN_SIGMA, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (setting focal #0 = 469.3912353515625)\n",
      " (setting focal #1 = 469.3912353515625)\n",
      " (setting focal #2 = 469.3912353515625)\n",
      " (setting focal #3 = 469.3912353515625)\n",
      " (setting focal #4 = 469.3912353515625)\n",
      " (setting focal #5 = 469.3912353515625)\n",
      " (setting focal #6 = 469.3912353515625)\n",
      " (setting focal #7 = 469.3912353515625)\n",
      " (setting focal #8 = 469.3912353515625)\n",
      " (setting focal #9 = 469.3912353515625)\n",
      " (setting focal #10 = 469.3912353515625)\n",
      " (setting focal #11 = 469.3912353515625)\n",
      " (setting focal #12 = 469.3912353515625)\n",
      " (setting focal #13 = 469.3912353515625)\n",
      " (setting focal #14 = 469.3912353515625)\n",
      " (setting focal #15 = 469.3912353515625)\n",
      " (setting focal #16 = 469.3912353515625)\n",
      " (setting focal #17 = 469.3912353515625)\n",
      " (setting focal #18 = 469.3912353515625)\n",
      " (setting focal #19 = 469.3912353515625)\n",
      " (setting pose #0 = [ 0.08369204 -0.23462954  0.15426631])\n",
      " (setting pose #1 = [ 0.06546892 -0.22099422  0.15435892])\n",
      " (setting pose #2 = [ 0.06222615 -0.21649924  0.15444268])\n",
      " (setting pose #3 = [ 0.05977247 -0.21203236  0.15451883])\n",
      " (setting pose #4 = [ 0.05779224 -0.20757374  0.1545779 ])\n",
      " (setting pose #5 = [ 0.05633058 -0.20302275  0.15451288])\n",
      " (setting pose #6 = [ 0.05544504 -0.19830985  0.1546334 ])\n",
      " (setting pose #7 = [ 0.05510638 -0.19341378  0.1546886 ])\n",
      " (setting pose #8 = [ 0.05533424 -0.18824676  0.15432344])\n",
      " (setting pose #9 = [ 0.05568622 -0.1830238   0.15456273])\n"
     ]
    }
   ],
   "source": [
    "scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PlanePointCloudOptimizer, \n",
    "                       weight_focal = 1, \n",
    "                       weight_z = 0.1, \n",
    "                       weight_rot = 0.1, \n",
    "                       weight_trans_smoothness = 0.001,\n",
    "                       weight_rot_smoothness = 0.001)\n",
    "scene.preset_focal(preset_focal, [True for _ in range(PREVIOUS_FRAMES+NEW_FRAMES)])\n",
    "scene.preset_pose(preset_pose, preset_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (15*,18*) score=1.2693949937820435\n",
      " init edge (5*,18) score=1.2693949937820435\n",
      " init edge (5,8*) score=1.2693949937820435\n",
      " init edge (12*,18) score=1.2579251527786255\n",
      " init edge (2*,8) score=1.2579251527786255\n",
      " init edge (6*,18) score=1.2536730766296387\n",
      " init edge (14*,18) score=1.2412238121032715\n",
      " init edge (4*,18) score=1.2412238121032715\n",
      " init edge (6,19*) score=1.258823275566101\n",
      " init edge (6,9*) score=1.258823275566101\n",
      " init edge (3*,6) score=1.2579948902130127\n",
      " init edge (17*,19) score=1.2557786703109741\n",
      " init edge (7*,19) score=1.2557786703109741\n",
      " init edge (7,11*) score=1.214026689529419\n",
      " init edge (7,1*) score=1.214026689529419\n",
      " init edge (3,10*) score=1.1488021612167358\n",
      " init edge (3,0*) score=1.1488021612167358\n",
      " init edge (16*,19) score=1.258823275566101\n",
      " init edge (13*,16) score=1.2579948902130127\n",
      " init loss = 0.07411404699087143\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps.0', 'im_depthmaps.1', 'im_depthmaps.2', 'im_depthmaps.3', 'im_depthmaps.4', 'im_depthmaps.5', 'im_depthmaps.6', 'im_depthmaps.7', 'im_depthmaps.8', 'im_depthmaps.9', 'im_depthmaps.10', 'im_depthmaps.11', 'im_depthmaps.12', 'im_depthmaps.13', 'im_depthmaps.14', 'im_depthmaps.15', 'im_depthmaps.16', 'im_depthmaps.17', 'im_depthmaps.18', 'im_depthmaps.19', 'im_poses.10', 'im_poses.11', 'im_poses.12', 'im_poses.13', 'im_poses.14', 'im_poses.15', 'im_poses.16', 'im_poses.17', 'im_poses.18', 'im_poses.19']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:18<00:00,  1.06s/it, lr=1.27413e-06 loss=0.00091122] \n"
     ]
    }
   ],
   "source": [
    "loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(confidence_masks[PREVIOUS_FRAMES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': 'masked_images/50.png', 'transform_matrix': [[-0.730869710445404, -0.5621897578239441, 0.38700374960899353, 0.06657484173774719], [0.6821752190589905, -0.6196547150611877, 0.38815563917160034, -0.22021174430847168], [0.02159157395362854, 0.5476956367492676, 0.8363988995552063, 0.1544608473777771], [0.0, 0.0, 0.0, 1.0]], 'mask_path': 'masks/50.png'}\n",
      "{'file_path': 'masked_images/51.png', 'transform_matrix': [[-0.715075671672821, -0.5763584971427917, 0.39557260274887085, 0.06622093915939331], [0.6987153887748718, -0.60672527551651, 0.37905314564704895, -0.21998773515224457], [0.021533414721488953, 0.5474443435668945, 0.8365650177001953, 0.15437352657318115], [0.0, 0.0, 0.0, 1.0]], 'mask_path': 'masks/51.png'}\n",
      "{'file_path': 'masked_images/52.png', 'transform_matrix': [[-0.6411790251731873, -0.6347156763076782, 0.4313070476055145, 0.06388243287801743], [0.7671033143997192, -0.545526921749115, 0.3375694155693054, -0.2170315980911255], [0.021028965711593628, 0.5472994446754456, 0.8366727828979492, 0.1543242186307907], [0.0, 0.0, 0.0, 1.0]], 'mask_path': 'masks/52.png'}\n",
      "{'file_path': 'masked_images/53.png', 'transform_matrix': [[-0.5556178092956543, -0.6891038417816162, 0.46521466970443726, 0.06154261529445648], [0.8311711549758911, -0.47452226281166077, 0.289798378944397, -0.21377883851528168], [0.02105352282524109, 0.547690212726593, 0.8364162445068359, 0.15443511307239532], [0.0, 0.0, 0.0, 1.0]], 'mask_path': 'masks/53.png'}\n",
      "{'file_path': 'masked_images/54.png', 'transform_matrix': [[-0.4607323408126831, -0.7370224595069885, 0.49449315667152405, 0.05932019278407097], [0.8872759938240051, -0.3960477113723755, 0.23640520870685577, -0.2099880427122116], [0.02160695195198059, 0.5476714968681335, 0.8364143967628479, 0.15453198552131653], [0.0, 0.0, 0.0, 1.0]], 'mask_path': 'masks/54.png'}\n",
      "{'file_path': 'masked_images/55.png', 'transform_matrix': [[-0.3610619902610779, -0.7761642336845398, 0.5169171094894409, 0.057726483792066574], [0.9323061108589172, -0.31290096044540405, 0.18137869238853455, -0.20618115365505219], [0.02096422016620636, 0.5474139451980591, 0.8365992903709412, 0.1545853316783905], [0.0, 0.0, 0.0, 1.0]], 'mask_path': 'masks/55.png'}\n",
      "{'file_path': 'masked_images/56.png', 'transform_matrix': [[-0.2581917643547058, -0.8053362369537354, 0.5336391925811768, 0.05660443753004074], [0.9658536911010742, -0.22748762369155884, 0.12400037050247192, -0.20214086771011353], [0.02153429388999939, 0.5474331974983215, 0.8365723490715027, 0.1546219289302826], [0.0, 0.0, 0.0, 1.0]], 'mask_path': 'masks/56.png'}\n",
      "{'file_path': 'masked_images/57.png', 'transform_matrix': [[-0.15007245540618896, -0.8254569172859192, 0.5441499352455139, 0.05584825947880745], [0.9884560704231262, -0.13685309886932373, 0.065007284283638, -0.19803310930728912], [0.020807862281799316, 0.5476241111755371, 0.8364657759666443, 0.15460802614688873], [0.0, 0.0, 0.0, 1.0]], 'mask_path': 'masks/57.png'}\n",
      "{'file_path': 'masked_images/58.png', 'transform_matrix': [[-0.038869649171829224, -0.8357654809951782, 0.5477092266082764, 0.05572456493973732], [0.999014139175415, -0.04426887631416321, 0.0033465027809143066, -0.19380904734134674], [0.02144959568977356, 0.547299325466156, 0.8366621732711792, 0.15462861955165863], [0.0, 0.0, 0.0, 1.0]], 'mask_path': 'masks/58.png'}\n",
      "{'file_path': 'masked_images/59.png', 'transform_matrix': [[0.07305184006690979, -0.8352468609809875, 0.545001208782196, 0.05562153458595276], [0.9970994591712952, 0.04946073889732361, -0.057849496603012085, -0.1895592212677002], [0.02136242389678955, 0.5476464033126831, 0.8364373445510864, 0.1546517312526703], [0.0, 0.0, 0.0, 1.0]], 'mask_path': 'masks/59.png'}\n"
     ]
    }
   ],
   "source": [
    "imgs = scene.imgs\n",
    "focals = scene.get_focals()\n",
    "poses = scene.get_im_poses()\n",
    "pts3d = scene.get_pts3d()\n",
    "confidence_masks = scene.get_masks()\n",
    "\n",
    "for i in range(PREVIOUS_FRAMES, PREVIOUS_FRAMES+NEW_FRAMES):\n",
    "    new_frame = {\n",
    "        \"file_path\" : \"/\".join(images_array[i].split(\"/\")[-2:]),\n",
    "        \"transform_matrix\" : poses[i].tolist(),\n",
    "        \"mask_path\" : \"/\".join(masks_array[i].split(\"/\")[-2:])\n",
    "    }\n",
    "    if confidence_masks[i].sum() > 0:\n",
    "        transforms[\"frames\"].append(new_frame)\n",
    "    else:\n",
    "        print(\"Reject frame {} due to low confidence\".format(i))\n",
    "\n",
    "with open(f\"{DATA_PATH}/transforms.json\", \"w\") as f:\n",
    "    json.dump(transforms, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
